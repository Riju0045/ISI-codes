{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riju0045/ISI-codes/blob/main/churnmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n"
      ],
      "metadata": {
        "id": "GFiPviuXuCmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/internship project/final_data_updated.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Fg2YsFV_uDGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Churn'] = df['Refunded Amount'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "df['Churn'].value_counts()\n"
      ],
      "metadata": {
        "id": "G71H8ChUuIHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Churn', 'Refunded Amount'], axis=1)\n",
        "y = df['Churn']\n"
      ],
      "metadata": {
        "id": "cZ9Vf4esuS1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['Shipping Method', 'Payment Method', 'Source']\n",
        "\n",
        "\n",
        "X_selected = X.copy()\n",
        "\n",
        "\n",
        "X_encoded = pd.get_dummies(X_selected, columns=categorical_cols)\n",
        "\n",
        "\n",
        "if 'Vendor' in X_encoded.columns:\n",
        "    X_encoded = X_encoded.drop(columns=['Vendor'])\n"
      ],
      "metadata": {
        "id": "hDY96T-6uYJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "X = X_encoded\n",
        "y = df['Churn']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Before SMOTE:\", y_train.value_counts())\n",
        "print(\"After SMOTE:\", y_train_resampled.value_counts())\n"
      ],
      "metadata": {
        "id": "tVXBNHZsuxYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_numeric = X_train.select_dtypes(include=['object']).columns\n",
        "print(\"Non-numeric columns:\", non_numeric)\n"
      ],
      "metadata": {
        "id": "9PMyXdeMvamC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.drop(columns=non_numeric)\n",
        "X_test = X_test.drop(columns=non_numeric)\n"
      ],
      "metadata": {
        "id": "KXzUACs7vbDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "EFaMFN0Mvfq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n"
      ],
      "metadata": {
        "id": "-7ybo23kvhN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "yzCQ1y1Cvl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "pdmpgbuPvspZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "hssBvVN0vv0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label='ROC Curve')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('AUC-ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"AUC Score:\", roc_auc_score(y_test, y_probs))\n"
      ],
      "metadata": {
        "id": "4urEuWsrvxou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'churn_model.pkl')\n"
      ],
      "metadata": {
        "id": "UPjN-GjCv2Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = joblib.load('churn_model.pkl')\n",
        "\n",
        "y_pred_new = loaded_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "SGZ9Q6vqv6Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(X_train.columns.tolist(), 'feature_columns.pkl')\n"
      ],
      "metadata": {
        "id": "Ckxd50Q2v7rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "threshold = 0.3\n",
        "\n",
        "y_pred_custom = (y_probs >= threshold).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
        "\n",
        "print(f\" Accuracy: {accuracy_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\" Recall (Churned customers): {recall_score(y_test, y_pred_custom):.4f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_custom))\n",
        "\n"
      ],
      "metadata": {
        "id": "nKkGeYgHv_fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_with_preds = X_test.copy()\n",
        "X_test_with_preds['Actual_Churn'] = y_test.values\n",
        "X_test_with_preds['Predicted_Churn'] = y_pred_custom\n",
        "X_test_with_preds['Churn_Probability'] = y_probs\n"
      ],
      "metadata": {
        "id": "4p1EifywxOge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churned_customers = X_test_with_preds[X_test_with_preds['Predicted_Churn'] == 1]\n",
        "print(\" High-risk churn customers:\\n\", churned_customers.head())\n"
      ],
      "metadata": {
        "id": "w8Xjc0zIxO95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, classification_report\n",
        "\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "threshold = 0.2\n",
        "y_pred_custom = (y_probs >= threshold).astype(int)\n",
        "\n",
        "print(f\" Accuracy: {accuracy_score(y_test, y_pred_custom):.4f}\")\n",
        "print(f\" Recall (Churned customers): {recall_score(y_test, y_pred_custom):.4f}\")\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_custom))\n"
      ],
      "metadata": {
        "id": "2coIgR0LxQp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_with_preds = X_test.copy()\n",
        "X_test_with_preds['Actual_Churn'] = y_test.values\n",
        "X_test_with_preds['Predicted_Churn'] = y_pred_custom\n",
        "X_test_with_preds['Churn_Probability'] = y_probs\n",
        "\n",
        "X_test_with_preds.to_csv('churn_predictions_threshold_0.2.csv', index=False)\n",
        "print(\" Saved: churn_predictions_threshold_0.2.csv\")\n"
      ],
      "metadata": {
        "id": "80QM6TbdxvEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9OX1AfQx2Wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}