{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riju0045/ISI-codes/blob/main/ISI_project_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NuvShzkj2pI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"final_data_for_Ideas_proj(1).xlsx\")\n",
        "df.head()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xls = pd.ExcelFile(\"final_data_for_Ideas_proj(1).xlsx\")\n",
        "sheet1 = pd.read_excel(xls, \"Sheet1\")\n",
        "sheet2 = pd.read_excel(xls, \"Sheet2\")\n",
        "sheet3 = pd.read_excel(xls, \"Sheet3\")\n"
      ],
      "metadata": {
        "id": "mTuMFUsML2Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 spending customers by average sales showing in vertical bars:\n",
        "import matplotlib.pyplot as plt\n",
        "customer_spending = sheet1.groupby(\"Billing name\")[\"Total\"].sum().reset_index()\n",
        "customer_spending.columns = [\"Billing name\", \"Total Spend\"]\n",
        "top_10_customers = customer_spending.sort_values(by=\"Total Spend\", ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x=\"Billing name\", y=\"Total Spend\", data=top_10_customers, palette=\"viridis\")\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt=\"%.2f\", label_type=\"edge\")\n",
        "plt.title(\"Top 10 Spending Customers\")\n",
        "plt.xlabel(\"Customer Name\")\n",
        "plt.ylabel(\"Total Spend\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QqW-dY9_SUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 spending customers by average sales showing in vertical bars:\n",
        "average_spend_per_customer = sheet1.groupby(\"Billing name\")[\"Total\"].mean().reset_index()\n",
        "average_spend_per_customer.columns = [\"Billing name\", \"Average Total Spend\"]\n",
        "top_10_avg_spend_customers = average_spend_per_customer.sort_values(by=\"Average Total Spend\", ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x=\"Billing name\", y=\"Average Total Spend\", data=top_10_avg_spend_customers, palette=\"viridis\")\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt=\"%.2f\", label_type=\"edge\")\n",
        "plt.title(\"Top 10 Customers by Average Spend\")\n",
        "plt.xlabel(\"Customer Name\")\n",
        "plt.ylabel(\"Average Total Spend\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wu-Q8pzWQLMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 customer by count the number of orders:\n",
        "import matplotlib.pyplot as plt\n",
        "order_frequency = sheet1['Billing name'].value_counts().reset_index()\n",
        "order_frequency.columns = ['Billing name', 'Order Count']\n",
        "top_10_freq_customers = order_frequency.sort_values(by='Order Count', ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Billing name', y='Order Count', data=top_10_freq_customers, palette='viridis')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, label_type='edge')\n",
        "plt.title('Top 10 Customers by Order Frequency')\n",
        "plt.xlabel('Customer Name')\n",
        "plt.ylabel('Order Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tX4bdUCrShGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 cities by total sales showing by bar plot (using the standardized data):\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "# Create variation of kolkata as a standardized City column\n",
        "kolkata_variations = ['Kolkata', 'kolkata','KOLKATA', 'CALCUTTA', 'Calcutta'] # Add more variations as needed\n",
        "df['Standardized City'] = df['Billing City'].apply(lambda x: 'Kolkata' if x in kolkata_variations else x)\n",
        "city_sales_standardized = df.groupby('Standardized City')['Total'].sum().reset_index().sort_values(by='Total', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(data=city_sales_standardized.head(10), x='Standardized City', y='Total', palette='plasma')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "sns.barplot(data=city_sales_standardized.head(10), x='Standardized City', y='Total', palette='plasma')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Top 10 Cities by Total Sales')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uOx3OyfIQkRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top 10 cities by average sales showing by bar plot (using the standardized data):\n",
        "import matplotlib.pyplot as plt\n",
        "city_avg_sales = sheet1.groupby(\"Billing City\")[\"Total\"].mean().sort_values(ascending=False).head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x=city_avg_sales.index, y=city_avg_sales.values, palette=\"plasma\")\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "plt.title(\"Top 10 Cities by Average Sales\")\n",
        "plt.xlabel(\"City\")\n",
        "plt.ylabel(\"Average Sales\")\n",
        "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
        "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3mczfHi3Uqty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 shipping vs. billing province by average sales:\n",
        "import matplotlib.pyplot as plt\n",
        "province_avg_sales = sheet1.groupby([\"Billing Province Name\", \"Shipping Province Name\"])[\"Total\"].mean().reset_index()\n",
        "top_10_province_sales = province_avg_sales.sort_values(by='Total', ascending=False).head(10)\n",
        "top_10_province_sales['Billing vs Shipping'] = top_10_province_sales['Billing Province Name'] + ' vs ' + top_10_province_sales['Shipping Province Name']\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.barplot(x='Total', y='Billing vs Shipping', data=top_10_province_sales, palette='plasma')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "plt.title('Top 10 Shipping vs Billing Province by Average Sales')\n",
        "plt.xlabel('Average Sales')\n",
        "plt.ylabel('Billing vs Shipping Province')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Top 10 Shipping vs Billing Province by Average Sales:\")\n",
        "print(top_10_province_sales[['Billing Province Name', 'Shipping Province Name', 'Total']])\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s3CKqyA8UvnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total Sales by Standardized Vendor (Top 10) by Vertical Bar Plot:\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "keventer_variations = ['Keventer', 'keventer', 'KEVENTER', 'Keventers', 'Keventer '] # Add more variations as needed\n",
        "# Create a standardized Vendor column\n",
        "sheet1['Standardized Vendor'] = sheet1['Vendor'].astype(str).apply(lambda x: 'Keventer' if x.strip() in [v.strip() for v in keventer_variations] else x)\n",
        "vendor_perf_standardized = sheet1.groupby(\"Standardized Vendor\").agg({\n",
        "    \"Total\": \"sum\",          # Total sales for the vendor\n",
        "    \"Discount Amount\": \"mean\", # Average discount offered by the vendor\n",
        "    \"Name\": \"nunique\" # Number of unique orders (frequency)\n",
        "}).reset_index()\n",
        "vendor_perf_standardized.rename(columns={'Name': 'Number of Orders'}, inplace=True)\n",
        "top_vendors_standardized = vendor_perf_standardized.sort_values(\"Total\", ascending=False)\n",
        "# Visualize Total Sales by Standardized Vendor (Top 10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Standardized Vendor', y='Total', data=top_vendors_standardized.head(10), palette='PuRd')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "plt.title('Total Sales by Vendor')\n",
        "plt.xlabel('Total Sales')\n",
        "plt.ylabel('Vendor')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dxhf3jmzWK1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Order Frequency by Standardized Vendor (Top 10 by Sales) by Vertical Bar Plot:\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Standardized Vendor', y='Number of Orders', data=top_vendors_standardized.head(10), palette='plasma')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, label_type='edge')\n",
        "plt.title('Order Frequency by Top Vendors')\n",
        "plt.xlabel('Vendor')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rgGrH_CsYziS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average Discount by Vendors by bar plot in decreasing order:\n",
        "import matplotlib.pyplot as plt\n",
        "average_discount_by_vendor = sheet1.groupby('Standardized Vendor')['Discount Amount'].mean().sort_values(ascending=False).reset_index()\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Standardized Vendor', y='Discount Amount', data=average_discount_by_vendor, palette='viridis')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
        "plt.title(\"Average Discount by Vendors\")\n",
        "plt.xlabel('Vendor')\n",
        "plt.ylabel('Average Discount Amount')\n",
        "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-gLHYzvuZF1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "df = pd.read_excel(\"class.model.1.xlsx\")\n",
        "df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NW6I7XMOFpUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification models:\n",
        "# 1. Logistic regression\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# --- Load the Excel sheet ---\n",
        "file_path = \"class.model.1.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"Sheet1\")\n",
        "df[\"Discount Used\"] = df[\"Discount Amount\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "features = [ \"Subtotal\", \"Total\", \"Vendor\", \"Hour\", \"Month\", \"Day\", \"Lineitem price\", \"Lineitem compare at price\" ]\n",
        "df = df.dropna(subset=features + [\"Discount Used\"])\n",
        "# --- Prepare feature matrix and target variable ---\n",
        "X = df[features]\n",
        "y = df[\"Discount Used\"]\n",
        "numeric = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "# --- Preprocessing pipeline ---\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numeric),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical)\n",
        "])\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42))\n",
        "])\n",
        "# --- Train-test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "# --- AUC Score ---\n",
        "print(\"AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "# --- Confusion Matrix ---\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"YlGnBu\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# --- ROC Curve ---\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.plot(fpr, tpr, label=\"ROC curve (AUC = %.2f)\" % roc_auc_score(y_test, y_proba))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve for Discount Usage Prediction(by Logistic Model)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xjYGJLmBfprO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Top Features Influencing Discount Usage from the trained Random Forest\n",
        "import numpy as np\n",
        "ohe = model.named_steps['preprocessor'].named_transformers_['cat']\n",
        "cat_features = ohe.get_feature_names_out(categorical)\n",
        "all_features = numeric + cat_features.tolist()\n",
        "# Get importance from the Random Forest  classifier\n",
        "rf = model.named_steps['classifier']\n",
        "importances = rf.feature_importances_\n",
        "feat_imp = pd.Series(importances, index=all_features).sort_values(ascending=False)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=feat_imp, y=feat_imp.index, palette=\"plasma\")\n",
        "plt.title(\"Top Features Influencing Discount Usage\", fontsize=16)\n",
        "plt.xlabel(\"Importance Score\", fontsize=12)\n",
        "plt.ylabel(\"Features\", fontsize=12)\n",
        "for i, v in enumerate(feat_imp):\n",
        "    plt.text(v + 0.001, i, f\"{v:.3f}\", va='center', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k5h9GBoDXaq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classification models:\n",
        "# 2. DESICION TREE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score # Import roc_curve and roc_auc_score\n",
        "from sklearn.pipeline import Pipeline # Import Pipeline\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "from sklearn.compose import ColumnTransformer # Import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # Import StandardScaler and OneHotEncoder\n",
        "\n",
        "# Build the Decision Tree model pipeline\n",
        "dt_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42)) # Use a Decision Tree classifier\n",
        "])\n",
        "\n",
        "# Train the Decision Tree model\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "#confusion matrix for the Decision Tree model\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "disp_dt = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=['No Discount', 'Discount Used'])\n",
        "disp_dt.plot(cmap=\"plasma\")\n",
        "plt.title(\"Confusion Matrix (Decision Tree)\")\n",
        "plt.show()\n",
        "# Print classification report and AUC for the Decision Tree model\n",
        "print(\"\\nClassification Report (Decision Tree):\\n\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# AUC for the Decision Tree model\n",
        "y_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
        "dt_auc = roc_auc_score(y_test, y_proba_dt) # Calculate and store AUC\n",
        "print(\"AUC (Decision Tree):\", dt_auc)\n",
        "\n",
        "#ROC curve for the Decision Tree\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba_dt) # Use y_proba_dt for roc_curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=\"Decision Tree (AUC = %.2f)\" % dt_auc)\n",
        "plt.plot([0,1],[0,1],'k--') # Add the random guess line\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve( Decision Tree)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UnyHQm2jbnYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Top Features Influencing Discount Usage from the Decision Tree\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "dt_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "# Train the Decision Tree model\n",
        "dt_pipeline.fit(X_train, y_train)\n",
        "# Extract feature names after transformation\n",
        "ohe = dt_pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
        "cat_features = ohe.get_feature_names_out(categorical)\n",
        "all_features = numeric + cat_features.tolist()\n",
        "# Get importance from the Decision Tree classifier\n",
        "dt_classifier = dt_pipeline.named_steps['classifier']\n",
        "importances_dt = dt_classifier.feature_importances_\n",
        "feat_imp_dt = pd.Series(importances_dt, index=all_features).sort_values(ascending=False)\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=feat_imp_dt, y=feat_imp_dt.index, palette=\"viridis\") # Using a different colormap for clarity\n",
        "plt.title(\"Top Features Influencing Discount Usage (Decision Tree)\", fontsize=16)\n",
        "plt.xlabel(\"Importance Score\", fontsize=12)\n",
        "plt.ylabel(\"Features\", fontsize=12)\n",
        "for i, v in enumerate(feat_imp_dt):\n",
        "    plt.text(v + 0.001, i, f\"{v:.3f}\", va='center', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6HLnKgLrMBnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1611c7eb"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to read all sheets from the Excel file \"Sample - Superstore.xls\" into separate DataFrames. I will use pandas to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de832bae"
      },
      "source": [
        "Now that we have loaded the data from all four sheets, let's calculate the sum of sales and returns per vendor and visualize it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661bb399"
      },
      "source": [
        "### Understanding and Handling Class Imbalance\n",
        "\n",
        "**Class Imbalance** occurs when the number of instances in one class is significantly lower than the number of instances in other classes in your dataset. In your case, looking at the value counts for 'Premium Status', you can see if there's a large difference between the counts for class 0 and class 1.\n",
        "\n",
        "**Why is it a problem?**\n",
        "\n",
        "*   **Model Bias:** Standard machine learning algorithms tend to be biased towards the majority class because they aim to minimize overall error. This can lead to poor performance in predicting the minority class, which is often the class of most interest (e.g., predicting fraud, rare diseases, or in your case, potentially 'Premium Status' if it's the minority class).\n",
        "*   **Misleading Evaluation Metrics:** Metrics like accuracy can be misleading in the presence of severe class imbalance. A model that predicts the majority class for all instances might still achieve high accuracy, but it's not a useful model.\n",
        "\n",
        "**How to handle Class Imbalance?**\n",
        "\n",
        "There are several techniques to address class imbalance:\n",
        "\n",
        "1.  **Resampling Techniques:**\n",
        "    *   **Oversampling the minority class:** Creating synthetic or duplicating existing instances of the minority class (e.g., SMOTE).\n",
        "    *   **Undersampling the majority class:** Removing instances from the majority class.\n",
        "2.  **Using Different Evaluation Metrics:** Rely on metrics that are more informative for imbalanced datasets, such as:\n",
        "    *   **Precision, Recall, F1-score** (as seen in your classification report, but pay close attention to the scores for the minority class).\n",
        "    *   **Confusion Matrix:** Provides a detailed breakdown of true positives, true negatives, false positives, and false negatives.\n",
        "    *   **ROC AUC:** (Requires at least two classes in the test set) Measures the model's ability to distinguish between classes.\n",
        "    *   **Balanced Accuracy:** The average of recall obtained on each class.\n",
        "3.  **Using Algorithms Designed for Imbalance:** Some algorithms or their implementations have built-in ways to handle class imbalance (e.g., `scale_pos_weight` in some tree-based models, `class_weight='balanced'` in scikit-learn models).\n",
        "4.  **Generating Synthetic Data:** Techniques like SMOTE create synthetic minority class samples.\n",
        "\n",
        "Based on the distribution you observed, would you like to try implementing a technique to handle class imbalance before re-training and evaluating your models?"
      ]
    }
  ]
}